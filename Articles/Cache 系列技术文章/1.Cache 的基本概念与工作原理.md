# Cache 的基本概念与工作原理

## 1. 背景知识

随着 CPU 技术的飞速发展，常用的处理器飞奔在越来越高的频率之上，虽然处理器的速度越来越快，但是与之相匹配的存储器的速度却没有获得相应的提升，这大大限制了 CPU 的处理性能。而我们本系列文档所介绍的主角 Cache 技术就是用来解决这个难题的。

在 ARM 发布 Cortex-M7 架构之后，微控制器领域也出现了频率高达数百兆的芯片，如 ST 的 STM32F7 系列和 NXP 的 i.MX RT 系列芯片，这些芯片内的处理器都自带 cache，在合理配置下可以表现出十分强悍的数据处理性能。那么什么是 cache？如何利用这一新特性编写高性能的程序？又有什么要注意的地方吗？你可能会有上述这些疑问，别担心，本系列文章将会为你一一解答。

本系列文章分为三篇，第一篇为 《cache 的基本概念与工作原理》，讲解 cache 相关的基础知识。第二篇为《STM32F7 Cache 介绍与实战》，讲解如何在 STM32F7 系列芯片上使用 cache，并编写程序进行性能测试。第三篇为《Cache 的一致性问题与使用技巧》，将会介绍 cache 的数据一致性问题和使用 cache 过程中的一些技巧。下面我们从 cache 的基础知识开始，了解这一强大的特性吧。

## 2. 计算机的层次结构存储系统

想要理解 cache 的工作原理，就必须要了解计算机系统中数据的存储方式。

在计算机中程序执行时所有的指令和数据都是从存储器中取出来执行的。存储器是计算机系统中的重要组成部分，相当于计算机的仓库，用来存放各类程序及其处理的数据。因此存储器的容量和性能应当随着处理器的速度和性能的提高而通过提高，以保持系统性能的平衡。

然而在过去的 20 多年中，随着时间的推移，处理器和存储器在性能发展上的差异越来越大，存储器在容量尤其是访问延时方面的性能增长越来越跟不上处理器性能发展的需要。为了缩小存储器和处理器两者之间在性能方面的差距，通常在计算机内部采用层次化的存储器体系结构。

![1555224270606](assets/1555224270606.png)

从上图可以看到，速度越快则容量越小、越靠近 CPU。CPU 可以直接访问内部存储器。而外部存储器的信息则要先取到主存，然后才能被 CPU 访问。CPU 执行指令时，需要的操作数大部分来自寄存器，当需要对存储器进行读写操作时，先访问 cache ，如果不在 cache 中，则访问主存，如果不在主存中，则访问硬盘。此时，操作数从硬盘中读出送到主存，然后从主存送到 cache。

## 3. 为什么需要 Cache?

由于 CPU 和主存所使用的半导体器件工艺不同，两者速度上的差异导致快速的 CPU 等待慢速的存储器，为此需要想办法提高 CPU 访问主存的速度。除了提高 DRAM 芯片本身的速度和采用并行结构技术以外，加快 CPU 访存速度的主要方式之一是在 CPU 和主存之间增加高速缓冲器，也就是我们主角 Cache。

![1555230650567](assets/1555230650567.png)

Cache 位于 CPU 和内存之间，可以节省 CPU 从外部存储器读取指令和数据的时间。

## 4. 基本概念

- 程序访问的局部性
- I-Cache 
- D-cache 

## 5. 工作原理

- cache 的有效位
- CPU 在 cache 中的访问过程
- cache 与主存的平均访问时间
- cache 的映射方式